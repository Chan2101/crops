{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1010bff9",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸŒ¾ Crop Disease Risk â€” Experiments (Google Colab)\n",
    "\n",
    "This notebook runs **four experiments** using your datasets and saves figures + results tables.\n",
    "\n",
    "**Experiments:**\n",
    "1. **Exp1**: Random Forest Regression â€” Weather + Region (one-hot)  \n",
    "2. **Exp2**: Random Forest Regression â€” Weather only  \n",
    "3. **Exp3**: Per-Region models (RÂ² per region table)  \n",
    "4. **Exp4**: High-Risk Classification (HistGradientBoosting) + **Permutation Importance**  \n",
    "\n",
    "**Outputs created:**\n",
    "- `metrics_summary.csv` (summary table)  \n",
    "- `Exp3_PerRegion_R2.csv` (region-wise RÂ²)  \n",
    "- `Exp4_PermutationImportance.csv` (importance for classifier)  \n",
    "- SHAP bar plots for Exp1 & Exp2  \n",
    "- PDP/ICE plots for top features  \n",
    "- RÂ² and RMSE bar charts for experiment comparison  \n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“‚ How to provide data\n",
    "**Option A â€” Upload files (simple):**\n",
    "- When prompted, upload:\n",
    "  - `aggregated_weather_by_region_year.csv`\n",
    "  - `mean-time-series-wheat-regional-data-september-2024-1.xlsx`\n",
    "\n",
    "**Option B â€” Use Google Drive:**\n",
    "- Mount Drive and set `BASE` to your folder path inside Drive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2287cc81",
   "metadata": {},
   "source": [
    "## ðŸ”§ Setup & Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If running in Colab, install dependencies:\n",
    "# (Uncomment if needed)\n",
    "# !pip install pandas numpy scikit-learn shap matplotlib openpyxl\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, roc_auc_score, f1_score\n",
    "from sklearn.inspection import permutation_importance, PartialDependenceDisplay\n",
    "import shap\n",
    "\n",
    "print(\"âœ… Libraries imported.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6c9ccc",
   "metadata": {},
   "source": [
    "## ðŸ“¥ Provide Data (Upload or Drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c18bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import files\n",
    "\n",
    "# === Option A: Upload files ===\n",
    "print(\"ðŸ‘‰ Option A: Click to upload the two files when prompted.\")\n",
    "uploaded = files.upload()  # use file picker\n",
    "\n",
    "# File names expected (rename if your uploads differ)\n",
    "WEATHER_FILE = \"aggregated_weather_by_region_year.csv\"\n",
    "DISEASE_FILE = \"mean-time-series-wheat-regional-data-september-2024-1.xlsx\"\n",
    "\n",
    "# If user uploaded different names, try to map by extension/guess\n",
    "if WEATHER_FILE not in uploaded:\n",
    "    # guess a csv\n",
    "    for k in uploaded:\n",
    "        if k.lower().endswith(\".csv\"):\n",
    "            WEATHER_FILE = k\n",
    "            break\n",
    "\n",
    "if DISEASE_FILE not in uploaded:\n",
    "    for k in uploaded:\n",
    "        if k.lower().endswith(\".xlsx\"):\n",
    "            DISEASE_FILE = k\n",
    "            break\n",
    "\n",
    "print(\"Using files:\")\n",
    "print(\"  WEATHER_FILE:\", WEATHER_FILE)\n",
    "print(\"  DISEASE_FILE:\", DISEASE_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b03375",
   "metadata": {},
   "source": [
    "### (Optional) Use Google Drive Instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428e2850",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If you prefer Drive, run this cell instead of the upload cell above:\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# BASE = \"/content/drive/MyDrive/YourFolder\"  # <-- change to your folder\n",
    "# WEATHER_FILE = BASE + \"/aggregated_weather_by_region_year.csv\"\n",
    "# DISEASE_FILE = BASE + \"/mean-time-series-wheat-regional-data-september-2024-1.xlsx\"\n",
    "# print(\"Using Drive paths:\\n \", WEATHER_FILE, \"\\n \", DISEASE_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a5ceed",
   "metadata": {},
   "source": [
    "## ðŸ“š Load & Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0b23d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TARGET_DISEASE = \"Zymoseptoria_tritici\"  # change to Yellow_rust etc. if needed\n",
    "OUTDIR = \"./figs_results\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# Load\n",
    "weather = pd.read_csv(WEATHER_FILE)\n",
    "disease = pd.read_excel(DISEASE_FILE, skiprows=1)\n",
    "disease.columns = disease.columns.str.strip().str.replace(\" \", \"_\")\n",
    "\n",
    "# Keep only relevant columns\n",
    "disease = disease[['Region', 'Year', TARGET_DISEASE]].dropna()\n",
    "disease.columns = ['region', 'year', 'DiseaseSeverity']\n",
    "\n",
    "# Merge\n",
    "df = weather.merge(disease, on=['region', 'year'], how='inner').dropna()\n",
    "\n",
    "print(\"Weather shape:\", weather.shape)\n",
    "print(\"Disease shape:\", disease.shape)\n",
    "print(\"Merged shape :\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb85b17",
   "metadata": {},
   "source": [
    "## ðŸ§° Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c51279",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_regression(y_true, y_pred):\n",
    "    return {\n",
    "        \"RMSE\": mean_squared_error(y_true, y_pred, squared=False),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"R2\": r2_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "def save_metrics_table(results_dict, out_csv):\n",
    "    rows = []\n",
    "    for exp_name, m in results_dict.items():\n",
    "        row = {\"Experiment\": exp_name}\n",
    "        row.update(m)\n",
    "        rows.append(row)\n",
    "    pd.DataFrame(rows).to_csv(out_csv, index=False)\n",
    "    print(\"ðŸ’¾ Saved metrics table to:\", out_csv)\n",
    "\n",
    "def plot_metrics_bar(results_dict, out_r2_png):\n",
    "    exps = list(results_dict.keys())\n",
    "    r2s = [results_dict[k][\"R2\"] for k in exps]\n",
    "    rmses = [results_dict[k][\"RMSE\"] for k in exps]\n",
    "\n",
    "    # R2 bar\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.bar(exps, r2s)\n",
    "    plt.title(\"RÂ² by Experiment\")\n",
    "    plt.ylabel(\"RÂ²\")\n",
    "    plt.xticks(rotation=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_r2_png, dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "    # RMSE bar\n",
    "    out_rmse_png = out_r2_png.replace(\"R2\",\"RMSE\")\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.bar(exps, rmses)\n",
    "    plt.title(\"RMSE by Experiment\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.xticks(rotation=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_rmse_png, dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "def run_rf_regression_and_plots(X, y, label):\n",
    "    # Split\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    # Train\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    rf.fit(X_tr, y_tr)\n",
    "    # Predict\n",
    "    y_pred = rf.predict(X_te)\n",
    "    metrics = eval_regression(y_te, y_pred)\n",
    "\n",
    "    # SHAP bar\n",
    "    try:\n",
    "        explainer = shap.TreeExplainer(rf)\n",
    "        shap_vals = explainer.shap_values(X_te)\n",
    "        shap.summary_plot(shap_vals, X_te, plot_type=\"bar\", show=False)\n",
    "        plt.title(f\"SHAP Summary (bar) â€“ {label}\")\n",
    "        plt.tight_layout()\n",
    "        path = os.path.join(OUTDIR, f\"SHAP_bar_{label}.png\")\n",
    "        plt.savefig(path, dpi=200)\n",
    "        plt.show()\n",
    "        print(\"ðŸ’¾ Saved SHAP bar to:\", path)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] SHAP plot failed for {label}: {e}\")\n",
    "\n",
    "    # PDP/ICE for top 3 features by RF importance\n",
    "    try:\n",
    "        importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        top3 = list(importances.head(3).index)\n",
    "        for f in top3:\n",
    "            PartialDependenceDisplay.from_estimator(rf, X_tr, [f], kind=\"both\")\n",
    "            plt.suptitle(f\"PDP/ICE â€“ {label} â€“ {f}\")\n",
    "            plt.tight_layout()\n",
    "            path = os.path.join(OUTDIR, f\"PDP_ICE_{label}_{f}.png\")\n",
    "            plt.savefig(path, dpi=200)\n",
    "            plt.show()\n",
    "            print(\"ðŸ’¾ Saved PDP/ICE to:\", path)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] PDP/ICE failed for {label}: {e}\")\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1dc874",
   "metadata": {},
   "source": [
    "## ðŸš€ Run Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1c39b0",
   "metadata": {},
   "source": [
    "### Experiment 1 â€” Baseline (Weather + Region one-hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb62fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = {}\n",
    "\n",
    "E1 = \"Exp1_Baseline_Weather+Region\"\n",
    "X1 = df.drop(columns=['DiseaseSeverity'])\n",
    "X1 = pd.get_dummies(X1, columns=['region'], drop_first=True)\n",
    "y = df['DiseaseSeverity']\n",
    "\n",
    "results[E1] = run_rf_regression_and_plots(X1, y, E1)\n",
    "results[E1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a4488b",
   "metadata": {},
   "source": [
    "### Experiment 2 â€” Weather Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d99b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "E2 = \"Exp2_WeatherOnly\"\n",
    "X2 = df.drop(columns=['DiseaseSeverity','region','year'])\n",
    "\n",
    "results[E2] = run_rf_regression_and_plots(X2, y, E2)\n",
    "results[E2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e66bd1",
   "metadata": {},
   "source": [
    "### Experiment 3 â€” Per-Region Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dae3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "E3 = \"Exp3_PerRegion\"\n",
    "region_scores = []\n",
    "for reg in sorted(df['region'].unique()):\n",
    "    sub = df[df['region']==reg]\n",
    "    if len(sub) < 30:\n",
    "        continue\n",
    "    Xr = sub.drop(columns=['DiseaseSeverity','region','year'])\n",
    "    yr = sub['DiseaseSeverity']\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(Xr, yr, test_size=0.3, random_state=42)\n",
    "    rf = RandomForestRegressor(random_state=42).fit(X_tr, y_tr)\n",
    "    pred = rf.predict(X_te)\n",
    "    r2 = r2_score(y_te, pred)\n",
    "    region_scores.append({\"region\": reg, \"R2\": r2})\n",
    "\n",
    "region_df = pd.DataFrame(region_scores).sort_values(\"R2\", ascending=False)\n",
    "path = os.path.join(OUTDIR, \"Exp3_PerRegion_R2.csv\")\n",
    "region_df.to_csv(path, index=False)\n",
    "print(\"ðŸ’¾ Saved per-region RÂ² table to:\", path)\n",
    "\n",
    "# store mean R2 for summary\n",
    "results[E3] = {\"RMSE\": np.nan, \"MAE\": np.nan, \"R2\": region_df[\"R2\"].mean() if len(region_df) else np.nan}\n",
    "region_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347086d4",
   "metadata": {},
   "source": [
    "### Experiment 4 â€” High-Risk Classification + Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b4a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "E4 = \"Exp4_HighRisk_Classifier_PermImp\"\n",
    "thr = df['DiseaseSeverity'].quantile(0.75)\n",
    "df_cls = df.copy()\n",
    "df_cls[\"HighRisk\"] = (df_cls[\"DiseaseSeverity\"] >= thr).astype(int)\n",
    "\n",
    "Xc = df_cls.drop(columns=['region','year','DiseaseSeverity','HighRisk'])\n",
    "yc = df_cls['HighRisk']\n",
    "\n",
    "Xc_tr, Xc_te, yc_tr, yc_te = train_test_split(Xc, yc, test_size=0.3, random_state=42, stratify=yc)\n",
    "clf = HistGradientBoostingClassifier(random_state=42)\n",
    "clf.fit(Xc_tr, yc_tr)\n",
    "\n",
    "proba = clf.predict_proba(Xc_te)[:,1]\n",
    "pred  = (proba >= 0.5).astype(int)\n",
    "\n",
    "roc = roc_auc_score(yc_te, proba)\n",
    "f1  = f1_score(yc_te, pred)\n",
    "print(\"ROC-AUC:\", roc)\n",
    "print(\"F1     :\", f1)\n",
    "\n",
    "# Permutation importance\n",
    "perm = permutation_importance(clf, Xc_te, yc_te, n_repeats=15, random_state=42, scoring='roc_auc')\n",
    "perm_series = pd.Series(perm.importances_mean, index=Xc.columns).sort_values(ascending=False)\n",
    "perm_csv = os.path.join(OUTDIR, \"Exp4_PermutationImportance.csv\")\n",
    "perm_series.to_csv(perm_csv)\n",
    "print(\"ðŸ’¾ Saved permutation importance CSV to:\", perm_csv)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "perm_series.head(12).plot(kind='bar')\n",
    "plt.title(\"Permutation Importance (ROC-AUC) â€“ High-Risk Classifier\")\n",
    "plt.ylabel(\"Mean Importance (Î” ROC-AUC)\")\n",
    "plt.tight_layout()\n",
    "perm_png = os.path.join(OUTDIR, \"Exp4_PermImp_Top12.png\")\n",
    "plt.savefig(perm_png, dpi=200)\n",
    "plt.show()\n",
    "print(\"ðŸ’¾ Saved permutation importance plot to:\", perm_png)\n",
    "\n",
    "# store ROC in R2 slot for unified summary plotting\n",
    "results[E4] = {\"RMSE\": np.nan, \"MAE\": np.nan, \"R2\": roc}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9470e2b",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Save Metrics Summary + Bar Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84640878",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_metrics_bar(results_dict, out_r2_png):\n",
    "    exps = list(results_dict.keys())\n",
    "    r2s = [results_dict[k][\"R2\"] for k in exps]\n",
    "    rmses = [results_dict[k][\"RMSE\"] for k in exps]\n",
    "\n",
    "    # R2 bar\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.bar(exps, r2s)\n",
    "    plt.title(\"RÂ² by Experiment\")\n",
    "    plt.ylabel(\"RÂ²\")\n",
    "    plt.xticks(rotation=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_r2_png, dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "    # RMSE bar\n",
    "    out_rmse_png = out_r2_png.replace(\"R2\",\"RMSE\")\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.bar(exps, rmses)\n",
    "    plt.title(\"RMSE by Experiment\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.xticks(rotation=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_rmse_png, dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "metrics_csv = os.path.join(OUTDIR, \"metrics_summary.csv\")\n",
    "save_metrics_table(results, metrics_csv)\n",
    "\n",
    "plot_metrics_bar(results, os.path.join(OUTDIR, \"R2_by_Experiment.png\"))\n",
    "print(\"âœ… Done. See figures and tables in:\", OUTDIR)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}